{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as os, logging, and traceback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Configure logging to display information and error messages\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "Define the Config class that holds configuration paths and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Config class that holds configuration paths and settings\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Path to the database\n",
    "        self.DATA_BD_PATH = r\"C:\\Users\\yo\\Desktop\\jarvis_data\\databd\"\n",
    "        # Path to save the preprocessed data\n",
    "        self.CURRENT_PREPROCESSED_PATH = r\"C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define AdvancedDataPreprocessor Class\n",
    "Define the AdvancedDataPreprocessor class with methods for processing files in parallel and saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AdvancedDataPreprocessor class\n",
    "class AdvancedDataPreprocessor:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the preprocessor with the given configuration.\n",
    "        \n",
    "        Args:\n",
    "        config (dict): Configuration dictionary containing data paths, batch size, and max workers.\n",
    "        \"\"\"\n",
    "        self.data_paths = config['data_paths']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.max_workers = config['max_workers']\n",
    "        self.results = []\n",
    "\n",
    "    def process_files_parallel(self):\n",
    "        \"\"\"\n",
    "        Process files in parallel using the specified number of workers.\n",
    "        \"\"\"\n",
    "        # Placeholder for parallel processing logic\n",
    "        logging.info(\"Processing files in parallel with {} workers...\".format(self.max_workers))\n",
    "        # Simulate processing\n",
    "        for path in self.data_paths:\n",
    "            logging.info(f\"Processing file: {path}\")\n",
    "            self.results.append(f\"Processed {path}\")\n",
    "\n",
    "    def save_results(self, save_path):\n",
    "        \"\"\"\n",
    "        Save the processed results to the specified path.\n",
    "        \n",
    "        Args:\n",
    "        save_path (str): Path to save the processed results.\n",
    "        \"\"\"\n",
    "        # Placeholder for saving logic\n",
    "        logging.info(f\"Saving results to {save_path}\")\n",
    "        with open(save_path, 'w') as f:\n",
    "            for result in self.results:\n",
    "                f.write(result + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Configuration and Preprocessor\n",
    "Initialize the Config instance and set up the preprocessor configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing files in parallel with 12 workers...\n",
      "INFO:root:Processing file: C:\\Users\\yo\\Desktop\\jarvis_data\\databd\n",
      "INFO:root:Saving results to C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\n",
      "INFO:root:Preprocesamiento completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Initialize Configuration and Preprocessor\n",
    "\n",
    "# Create an instance of the Config class to access configuration paths and settings\n",
    "config_instance = Config()\n",
    "\n",
    "# Set up the preprocessor configuration dictionary\n",
    "preprocessor_config = {\n",
    "    'data_paths': [config_instance.DATA_BD_PATH],  # List of data paths to be processed\n",
    "    'batch_size': 32,  # Batch size for processing\n",
    "    'max_workers': os.cpu_count() or 4  # Number of workers for parallel processing\n",
    "}\n",
    "\n",
    "# Initialize the AdvancedDataPreprocessor with the configuration\n",
    "preprocessor = AdvancedDataPreprocessor(preprocessor_config)\n",
    "\n",
    "# Process the files in parallel using the preprocessor\n",
    "preprocessor.process_files_parallel()\n",
    "\n",
    "# Save the processed results to the specified path\n",
    "preprocessor.save_results(config_instance.CURRENT_PREPROCESSED_PATH)\n",
    "\n",
    "# Log the completion of preprocessing\n",
    "logging.info(\"Preprocesamiento completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Preprocessing\n",
    "Initialize and execute the preprocessor using the process_files_parallel method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing files in parallel with 12 workers...\n",
      "INFO:root:Processing file: C:\\Users\\yo\\Desktop\\jarvis_data\\databd\n",
      "INFO:root:Saving results to C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\n",
      "INFO:root:Preprocesamiento completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Execute Preprocessing\n",
    "\n",
    "# Initialize Configuration and Preprocessor\n",
    "\n",
    "# Create an instance of the Config class to access configuration paths and settings\n",
    "config_instance = Config()\n",
    "\n",
    "# Set up the preprocessor configuration dictionary\n",
    "preprocessor_config = {\n",
    "    'data_paths': [config_instance.DATA_BD_PATH],  # List of data paths to be processed\n",
    "    'batch_size': 32,  # Batch size for processing\n",
    "    'max_workers': os.cpu_count() or 4  # Number of workers for parallel processing\n",
    "}\n",
    "\n",
    "# Initialize the AdvancedDataPreprocessor with the configuration\n",
    "preprocessor = AdvancedDataPreprocessor(preprocessor_config)\n",
    "\n",
    "# Process the files in parallel using the preprocessor\n",
    "preprocessor.process_files_parallel()\n",
    "\n",
    "# Save the processed results to the specified path\n",
    "preprocessor.save_results(config_instance.CURRENT_PREPROCESSED_PATH)\n",
    "\n",
    "# Log the completion of preprocessing\n",
    "logging.info(\"Preprocesamiento completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results\n",
    "Save the preprocessing results to the specified path using the save_results method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving results to C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\n",
      "INFO:root:Preprocesamiento completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Save Results\n",
    "\n",
    "# Save the processed results to the specified path\n",
    "preprocessor.save_results(config_instance.CURRENT_PREPROCESSED_PATH)\n",
    "\n",
    "# Log the completion of preprocessing\n",
    "logging.info(\"Preprocesamiento completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Exceptions\n",
    "Handle any exceptions that occur during preprocessing and log the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing files in parallel with 12 workers...\n",
      "INFO:root:Processing file: C:\\Users\\yo\\Desktop\\jarvis_data\\databd\n",
      "INFO:root:Saving results to C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\n",
      "INFO:root:Preprocesamiento completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Handle Exceptions\n",
    "\n",
    "try:\n",
    "    # Initialize Configuration and Preprocessor\n",
    "    config_instance = Config()\n",
    "    preprocessor_config = {\n",
    "        'data_paths': [config_instance.DATA_BD_PATH],\n",
    "        'batch_size': 32,\n",
    "        'max_workers': os.cpu_count() or 4\n",
    "    }\n",
    "    \n",
    "    # Initialize and execute preprocessor\n",
    "    preprocessor = AdvancedDataPreprocessor(preprocessor_config)\n",
    "    preprocessor.process_files_parallel()\n",
    "    \n",
    "    # Save results\n",
    "    preprocessor.save_results(config_instance.CURRENT_PREPROCESSED_PATH)\n",
    "    \n",
    "    logging.info(\"Preprocesamiento completado exitosamente\")\n",
    "    success = True\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f\"Error en el preprocesamiento: {e}\")\n",
    "    traceback.print_exc()\n",
    "    success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main Function\n",
    "Define and run the main function to execute the preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing files in parallel with 12 workers...\n",
      "INFO:root:Processing file: C:\\Users\\yo\\Desktop\\jarvis_data\\databd\n",
      "INFO:root:Saving results to C:\\Users\\yo\\Desktop\\jarvis_data\\preprocessed\n",
      "INFO:root:Preprocesamiento completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Run Main Function\n",
    "\n",
    "# Define the main function to execute the preprocessing script\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize Configuration and Preprocessor\n",
    "        config_instance = Config()\n",
    "        preprocessor_config = {\n",
    "            'data_paths': [config_instance.DATA_BD_PATH],\n",
    "            'batch_size': 32,\n",
    "            'max_workers': os.cpu_count() or 4\n",
    "        }\n",
    "        \n",
    "        # Initialize and execute preprocessor\n",
    "        preprocessor = AdvancedDataPreprocessor(preprocessor_config)\n",
    "        preprocessor.process_files_parallel()\n",
    "        \n",
    "        # Save results\n",
    "        preprocessor.save_results(config_instance.CURRENT_PREPROCESSED_PATH)\n",
    "        \n",
    "        logging.info(\"Preprocesamiento completado exitosamente\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el preprocesamiento: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Run the main function if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
